"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[8421],{15759:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>t});const s=JSON.parse('{"id":"chapters/module-3-isaac/perception-planning","title":"Chapter 2: Isaac ROS Perception and Planning","description":"Hardware-accelerated perception, SLAM, and manipulation with Isaac ROS","source":"@site/docs/chapters/module-3-isaac/02-perception-planning.md","sourceDirName":"chapters/module-3-isaac","slug":"/chapters/module-3-isaac/perception-planning","permalink":"/Physical-AI-Humanoid-Robotics/docs/chapters/module-3-isaac/perception-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/ayeshadev283-max/Physical-AI-Humanoid-Robotics/tree/main/docs/chapters/module-3-isaac/02-perception-planning.md","tags":[{"inline":true,"label":"isaac-ros","permalink":"/Physical-AI-Humanoid-Robotics/docs/tags/isaac-ros"},{"inline":true,"label":"perception","permalink":"/Physical-AI-Humanoid-Robotics/docs/tags/perception"},{"inline":true,"label":"slam","permalink":"/Physical-AI-Humanoid-Robotics/docs/tags/slam"},{"inline":true,"label":"manipulation","permalink":"/Physical-AI-Humanoid-Robotics/docs/tags/manipulation"},{"inline":true,"label":"nitros","permalink":"/Physical-AI-Humanoid-Robotics/docs/tags/nitros"}],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Chapter 2: Isaac ROS Perception and Planning","description":"Hardware-accelerated perception, SLAM, and manipulation with Isaac ROS","tags":["isaac-ros","perception","slam","manipulation","nitros"]},"sidebar":"bookSidebar","previous":{"title":"Chapter 1: NVIDIA Isaac Overview","permalink":"/Physical-AI-Humanoid-Robotics/docs/chapters/module-3-isaac/overview"},"next":{"title":"Chapter 3: Sim-to-Real Transfer","permalink":"/Physical-AI-Humanoid-Robotics/docs/chapters/module-3-isaac/sim-to-real"}}');var r=i(74848),o=i(28453);const a={sidebar_position:2,title:"Chapter 2: Isaac ROS Perception and Planning",description:"Hardware-accelerated perception, SLAM, and manipulation with Isaac ROS",tags:["isaac-ros","perception","slam","manipulation","nitros"]},l="Chapter 2: Isaac ROS Perception and Planning",c={},t=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"2.1 Isaac ROS Perception",id:"21-isaac-ros-perception",level:2},{value:"DNN Inference (TensorRT)",id:"dnn-inference-tensorrt",level:3},{value:"NITROS (Zero-Copy Messaging)",id:"nitros-zero-copy-messaging",level:3},{value:"2.2 Isaac ROS Navigation",id:"22-isaac-ros-navigation",level:2},{value:"Visual SLAM",id:"visual-slam",level:3},{value:"Nvblox (3D Mapping)",id:"nvblox-3d-mapping",level:3},{value:"2.3 Isaac ROS Manipulation",id:"23-isaac-ros-manipulation",level:2},{value:"Object Pose Estimation (DOPE)",id:"object-pose-estimation-dope",level:3},{value:"Motion Planning (cuRobo)",id:"motion-planning-curobo",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Summary",id:"summary",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"chapter-2-isaac-ros-perception-and-planning",children:"Chapter 2: Isaac ROS Perception and Planning"})}),"\n",(0,r.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Implement GPU-accelerated perception with Isaac ROS"}),"\n",(0,r.jsx)(e.li,{children:"Deploy visual SLAM for autonomous navigation"}),"\n",(0,r.jsx)(e.li,{children:"Integrate motion planning for manipulation tasks"}),"\n"]}),"\n",(0,r.jsx)(e.mermaid,{value:"graph LR\r\n    Camera[Camera<br/>sensor_msgs/Image] --\x3e|NITROS| Debayer[Debayer<br/>GPU]\r\n    Debayer --\x3e|NITROS| Rectify[Rectify<br/>GPU]\r\n    Rectify --\x3e|NITROS| DNN[DNN Inference<br/>TensorRT]\r\n    DNN --\x3e Detections[Detections<br/>vision_msgs]\r\n\r\n    Depth[Depth Camera] --\x3e|NITROS| Nvblox[Nvblox<br/>3D Mapping]\r\n    Nvblox --\x3e Costmap[Costmap<br/>nav_msgs]\r\n    Costmap --\x3e Nav2[Nav2 Planner]\r\n\r\n    IMU[IMU] --\x3e VSLAM[Visual SLAM]\r\n    Camera --\x3e|NITROS| VSLAM\r\n    VSLAM --\x3e Odometry[Odometry<br/>nav_msgs]\r\n\r\n    style Camera fill:#ffe1cc\r\n    style DNN fill:#ccffcc\r\n    style Nvblox fill:#cce1ff\r\n    style VSLAM fill:#ffffcc"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Figure 2.1"}),": Isaac ROS perception pipeline showing zero-copy NITROS communication between GPU-accelerated nodes. All image processing stays on GPU for minimal latency."]}),"\n",(0,r.jsx)(e.h2,{id:"21-isaac-ros-perception",children:"2.1 Isaac ROS Perception"}),"\n",(0,r.jsx)(e.h3,{id:"dnn-inference-tensorrt",children:"DNN Inference (TensorRT)"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"isaac_ros_dnn_inference"}),": GPU-accelerated deep learning"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Workflow"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Train model (PyTorch, TensorFlow)"}),"\n",(0,r.jsx)(e.li,{children:"Convert to ONNX"}),"\n",(0,r.jsx)(e.li,{children:"Optimize with TensorRT (FP16/INT8 quantization)"}),"\n",(0,r.jsx)(e.li,{children:"Deploy with Isaac ROS"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Example"})," (Object Detection):"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# Convert PyTorch to ONNX\r\nimport torch\r\nmodel = torch.load('yolov8.pth')\r\ntorch.onnx.export(model, dummy_input, 'yolov8.onnx')\r\n\r\n# Optimize with TensorRT (command line)\r\ntrtexec --onnx=yolov8.onnx --saveEngine=yolov8.engine --fp16\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"ROS 2 Node"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"from isaac_ros_tensor_rt import TensorRTNode\r\n\r\ntensorrt_node = TensorRTNode(\r\n    model_file_path='yolov8.engine',\r\n    engine_file_path='yolov8.engine',\r\n    input_tensor_names=['images'],\r\n    input_binding_names=['images'],\r\n    output_tensor_names=['output0'],\r\n    output_binding_names=['output0']\r\n)\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Performance"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"YOLOv8: 5 FPS (CPU) \u2192 60 FPS (GPU/TensorRT)"}),"\n",(0,r.jsx)(e.li,{children:"SegFormer: 2 FPS (CPU) \u2192 30 FPS (GPU)"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"nitros-zero-copy-messaging",children:"NITROS (Zero-Copy Messaging)"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Problem"}),": ROS 2 message serialization overhead (10-50ms latency)"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"NITROS"}),": GPU-to-GPU message passing (no CPU copy)"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Benefits"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Lower latency (1-5ms)"}),"\n",(0,r.jsx)(e.li,{children:"Higher throughput (100+ FPS pipelines)"}),"\n",(0,r.jsx)(e.li,{children:"Reduced CPU load"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Example"}),": Camera \u2192 Debayer \u2192 Rectify \u2192 DNN"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Standard ROS 2: 50ms latency"}),"\n",(0,r.jsx)(e.li,{children:"NITROS: 10ms latency"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"22-isaac-ros-navigation",children:"2.2 Isaac ROS Navigation"}),"\n",(0,r.jsx)(e.h3,{id:"visual-slam",children:"Visual SLAM"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"isaac_ros_visual_slam"}),": GPU-accelerated ORB-SLAM3"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Features"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Real-time: 30 Hz with 1MP camera"}),"\n",(0,r.jsx)(e.li,{children:"Stereo or monocular"}),"\n",(0,r.jsx)(e.li,{children:"Loop closure detection"}),"\n",(0,r.jsx)(e.li,{children:"Map persistence (save/load)"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Setup"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"ros2 launch isaac_ros_visual_slam isaac_ros_visual_slam.launch.py\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Subscribed Topics"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"/camera/image_raw"})," (sensor_msgs/Image)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"/camera/camera_info"})," (sensor_msgs/CameraInfo)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"/imu"})," (sensor_msgs/Imu) - optional"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Published Topics"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"/visual_slam/tracking/odometry"})," (nav_msgs/Odometry)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"/visual_slam/tracking/vo_pose"})," (geometry_msgs/PoseStamped)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"/visual_slam/vis/observations_cloud"})," (sensor_msgs/PointCloud2)"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Use Cases"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Indoor navigation without LiDAR"}),"\n",(0,r.jsx)(e.li,{children:"Drone SLAM (lightweight, visual-only)"}),"\n",(0,r.jsx)(e.li,{children:"AR/VR tracking"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"nvblox-3d-mapping",children:"Nvblox (3D Mapping)"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"isaac_ros_nvblox"}),": GPU voxel hashing for 3D reconstruction"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Features"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Real-time mapping (30 Hz with depth camera)"}),"\n",(0,r.jsx)(e.li,{children:"ESDF (Euclidean Signed Distance Field) for path planning"}),"\n",(0,r.jsx)(e.li,{children:"Mesh output for visualization"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Pipeline"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Depth camera \u2192 Point cloud"}),"\n",(0,r.jsx)(e.li,{children:"Nvblox integrates into voxel map"}),"\n",(0,r.jsx)(e.li,{children:"ESDF computed on GPU"}),"\n",(0,r.jsx)(e.li,{children:"Planner queries ESDF for collision-free paths"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Example"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"ros2 launch isaac_ros_nvblox isaac_ros_nvblox.launch.py\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Integration with Nav2"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Nvblox publishes costmap"}),"\n",(0,r.jsx)(e.li,{children:"Nav2 uses for obstacle avoidance"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"23-isaac-ros-manipulation",children:"2.3 Isaac ROS Manipulation"}),"\n",(0,r.jsx)(e.h3,{id:"object-pose-estimation-dope",children:"Object Pose Estimation (DOPE)"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"DOPE"})," (Deep Object Pose Estimation): 6-DOF pose from RGB"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Workflow"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Train DOPE on synthetic data (Isaac Sim)"}),"\n",(0,r.jsx)(e.li,{children:"Deploy with Isaac ROS on Jetson"}),"\n",(0,r.jsx)(e.li,{children:"Get object pose \u2192 plan grasp"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Training in Isaac Sim"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# Generate synthetic data with Replicator\r\nimport omni.replicator.core as rep\r\n\r\n# Randomize object pose\r\nwith rep.trigger.on_frame():\r\n    rep.randomizer.scatter_3d(\r\n        objects=rep.get.prims(path_pattern="/World/Objects/*"),\r\n        surface_prims="/World/Ground",\r\n        check_for_collisions=True\r\n    )\n'})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Inference"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"ros2 launch isaac_ros_dope isaac_ros_dope.launch.py\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Output"}),": ",(0,r.jsx)(e.code,{children:"geometry_msgs/PoseStamped"})," for each detected object"]}),"\n",(0,r.jsx)(e.h3,{id:"motion-planning-curobo",children:"Motion Planning (cuRobo)"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"cuRobo"}),": GPU-accelerated motion planning"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Features"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Trajectory optimization (100-1000x faster than MoveIt)"}),"\n",(0,r.jsx)(e.li,{children:"Collision checking on GPU"}),"\n",(0,r.jsx)(e.li,{children:"Multi-arm support"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Example"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from curobo.wrap.reacher import MotionGenConfig, MotionGen\r\n\r\n# Load robot\r\nconfig = MotionGenConfig.from_urdf("robot.urdf")\r\nmotion_gen = MotionGen(config)\r\n\r\n# Plan to goal pose\r\nresult = motion_gen.plan_single(\r\n    goal_pose=target_pose,\r\n    start_state=current_joint_state\r\n)\r\n\r\n# Execute trajectory\r\nfor waypoint in result.trajectory:\r\n    robot.set_joint_positions(waypoint)\n'})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Performance"}),": 10ms planning time (vs 100ms+ for OMPL/MoveIt)"]}),"\n",(0,r.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 2.1"}),": TensorRT Model Conversion Pipeline"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Train a simple object detection model (YOLOv8 or MobileNet-SSD) on COCO dataset"}),"\n",(0,r.jsx)(e.li,{children:"Convert model from PyTorch \u2192 ONNX \u2192 TensorRT engine"}),"\n",(0,r.jsx)(e.li,{children:"Benchmark inference speed (FP32, FP16, INT8) on target hardware"}),"\n",(0,r.jsx)(e.li,{children:"Document accuracy vs speed tradeoffs"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 2.2"}),": NITROS Performance Analysis"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Set up a perception pipeline: Camera \u2192 Debayer \u2192 Rectify \u2192 DNN Inference"}),"\n",(0,r.jsx)(e.li,{children:"Measure latency with standard ROS 2 messages vs NITROS"}),"\n",(0,r.jsx)(e.li,{children:"Profile CPU/GPU usage with both approaches"}),"\n",(0,r.jsx)(e.li,{children:"Create performance comparison chart"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 2.3"}),": Visual SLAM Deployment"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Deploy Isaac ROS Visual SLAM on a mobile robot or test rig"}),"\n",(0,r.jsx)(e.li,{children:"Collect odometry data while navigating a structured environment"}),"\n",(0,r.jsx)(e.li,{children:"Evaluate drift over time and loop closure performance"}),"\n",(0,r.jsx)(e.li,{children:"Compare with wheel odometry and sensor fusion results"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 2.4"}),": cuRobo Motion Planning"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Set up cuRobo for a robotic arm (e.g., UR5, Franka Emika)"}),"\n",(0,r.jsx)(e.li,{children:"Define collision geometry for workspace obstacles"}),"\n",(0,r.jsx)(e.li,{children:"Plan trajectories to 10 random goal poses"}),"\n",(0,r.jsx)(e.li,{children:"Measure planning time and compare with OMPL/MoveIt"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Perception"}),": TensorRT for DNN inference, NITROS for zero-copy, 10-100x speedup\r\n",(0,r.jsx)(e.strong,{children:"Navigation"}),": Visual SLAM (30 Hz), Nvblox (real-time 3D mapping), Nav2 integration\r\n",(0,r.jsx)(e.strong,{children:"Manipulation"}),": DOPE (6-DOF pose), cuRobo (GPU motion planning)"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Next"}),": Chapter 3 covers sim-to-real transfer strategies with Isaac Sim."]})]})}function h(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},28453:(n,e,i)=>{i.d(e,{R:()=>a,x:()=>l});var s=i(96540);const r={},o=s.createContext(r);function a(n){const e=s.useContext(o);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:a(n.components),s.createElement(o.Provider,{value:e},n.children)}}}]);