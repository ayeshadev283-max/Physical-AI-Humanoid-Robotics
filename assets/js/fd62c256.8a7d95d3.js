"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[7431],{28453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>l});var i=s(96540);const o={},r=i.createContext(o);function t(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:t(e.components),i.createElement(r.Provider,{value:n},e.children)}},58617:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"appendices/D-solutions","title":"Appendix D: Exercise Solutions","description":"Solutions to chapter exercises","source":"@site/docs/appendices/D-solutions.md","sourceDirName":"appendices","slug":"/appendices/D-solutions","permalink":"/Physical-AI-Humanoid-Robotics/docs/appendices/D-solutions","draft":false,"unlisted":false,"editUrl":"https://github.com/ayeshadev283-max/Physical-AI-Humanoid-Robotics/tree/main/docs/appendices/D-solutions.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Appendix D: Exercise Solutions","description":"Solutions to chapter exercises"},"sidebar":"bookSidebar","previous":{"title":"C: Setup Instructions","permalink":"/Physical-AI-Humanoid-Robotics/docs/appendices/C-setup-instructions"},"next":{"title":"Glossary","permalink":"/Physical-AI-Humanoid-Robotics/docs/glossary"}}');var o=s(74848),r=s(28453);const t={sidebar_position:4,title:"Appendix D: Exercise Solutions",description:"Solutions to chapter exercises"},l="Appendix D: Exercise Solutions",a={},c=[{value:"Module 0: Physical AI Foundations",id:"module-0-physical-ai-foundations",level:2},{value:"Chapter 1: Introduction",id:"chapter-1-introduction",level:3},{value:"Chapter 2: Embodied Intelligence",id:"chapter-2-embodied-intelligence",level:3},{value:"Chapter 3: Sensing and Perception",id:"chapter-3-sensing-and-perception",level:3},{value:"Chapter 4: Locomotion and Motor Control",id:"chapter-4-locomotion-and-motor-control",level:3},{value:"Module 1: ROS 2 Ecosystem",id:"module-1-ros-2-ecosystem",level:2},{value:"Module 2: Digital Twin",id:"module-2-digital-twin",level:2},{value:"Module 3: NVIDIA Isaac",id:"module-3-nvidia-isaac",level:2},{value:"Module 4: VLA Models",id:"module-4-vla-models",level:2},{value:"Module 5: Capstone Project",id:"module-5-capstone-project",level:2},{value:"Additional Practice Problems",id:"additional-practice-problems",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"appendix-d-exercise-solutions",children:"Appendix D: Exercise Solutions"})}),"\n",(0,o.jsx)(n.p,{children:"Solutions to exercises from each module. Try solving problems independently before consulting solutions."}),"\n",(0,o.jsx)(n.h2,{id:"module-0-physical-ai-foundations",children:"Module 0: Physical AI Foundations"}),"\n",(0,o.jsx)(n.h3,{id:"chapter-1-introduction",children:"Chapter 1: Introduction"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Exercise 1.1"}),": Define Physical AI and explain how it differs from traditional AI systems."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Solution"}),":\r\nPhysical AI refers to artificial intelligence systems that possess physical embodiment and interact with the real world through sensors and actuators. Key differences from traditional AI:"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Real-time constraints"}),": Must process sensor data and generate control commands within strict time limits (e.g., 100Hz for motor control)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Physical dynamics"}),": Must account for inertia, friction, and other physical phenomena"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Uncertainty"}),": Sensor noise, actuation errors, and environmental unpredictability"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Safety-critical"}),": Physical actions can cause damage or harm"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Embodiment"}),": The physical body itself contributes to computation (morphological computation)"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Traditional AI systems (e.g., language models, recommendation systems) operate in purely digital domains without these constraints."}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Exercise 1.2"}),": List three real-world applications of humanoid robots and their primary challenges."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Healthcare assistance"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Challenge: Safe physical interaction with vulnerable patients, unpredictable human behavior"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Warehouse automation"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Challenge: Dexterous manipulation of varied objects, navigation in dynamic environments"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Disaster response"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Challenge: Operating in unknown, hazardous environments with degraded communication"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h3,{id:"chapter-2-embodied-intelligence",children:"Chapter 2: Embodied Intelligence"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Exercise 2.1"}),": Explain the embodiment hypothesis with a concrete example."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Solution"}),":\r\nThe embodiment hypothesis states that intelligence emerges from the interaction between brain, body, and environment\u2014not from abstract reasoning alone."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Example"}),": Human infants learn object permanence through physical manipulation:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Reaching for objects \u2192 hand-eye coordination"}),"\n",(0,o.jsx)(n.li,{children:"Dropping objects \u2192 understanding gravity"}),"\n",(0,o.jsx)(n.li,{children:"Stacking blocks \u2192 learning balance and stability"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"A purely digital AI could learn these concepts from data, but an embodied robot learns them through sensorimotor experience, which may lead to more robust and generalizable understanding."}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Exercise 2.2"}),": Describe morphological computation and provide a robotics example."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Solution"}),":\r\nMorphological computation: Using the physical structure of a robot to simplify control problems."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Example"}),": Passive dynamic walkers"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Simple bipedal robots with no motors or sensors"}),"\n",(0,o.jsx)(n.li,{children:"Walk down slopes purely due to mechanical design (leg length, mass distribution, joint compliance)"}),"\n",(0,o.jsx)(n.li,{children:"Demonstrates that control complexity can be offloaded to body morphology"}),"\n",(0,o.jsx)(n.li,{children:"Modern application: Boston Dynamics uses leg compliance to absorb landing impacts without complex control"}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h3,{id:"chapter-3-sensing-and-perception",children:"Chapter 3: Sensing and Perception"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Exercise 3.1"}),": Design a sensor fusion system combining camera and LiDAR for obstacle detection."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class ObstacleDetector:\r\n    def __init__(self):\r\n        self.camera_sub = rospy.Subscriber('/camera/image', Image, self.camera_callback)\r\n        self.lidar_sub = rospy.Subscriber('/scan', LaserScan, self.lidar_callback)\r\n        \r\n    def fuse_sensors(self, camera_obstacles, lidar_obstacles):\r\n        \"\"\"\r\n        Sensor fusion logic:\r\n        - Camera: Good for classification (car, person, box)\r\n        - LiDAR: Accurate distance measurement\r\n        - Combine: Classified obstacles with precise 3D location\r\n        \"\"\"\r\n        fused_obstacles = []\r\n        for lidar_obs in lidar_obstacles:\r\n            # Find matching camera detection\r\n            for cam_obs in camera_obstacles:\r\n                if self.spatial_match(lidar_obs, cam_obs):\r\n                    fused_obstacles.append({\r\n                        'position': lidar_obs.position,  # Accurate from LiDAR\r\n                        'class': cam_obs.class_label,    # From camera\r\n                        'confidence': min(lidar_obs.conf, cam_obs.conf)\r\n                    })\r\n        return fused_obstacles\n"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Advantages"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"LiDAR provides accurate range (immune to lighting)"}),"\n",(0,o.jsx)(n.li,{children:"Camera provides semantic classification"}),"\n",(0,o.jsx)(n.li,{children:"Fusion improves robustness (redundancy if one sensor fails)"}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h3,{id:"chapter-4-locomotion-and-motor-control",children:"Chapter 4: Locomotion and Motor Control"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Exercise 4.1"}),": Calculate inverse kinematics for a 2-DOF planar arm."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,o.jsx)(n.p,{children:"Given:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Link lengths: L\u2081 = 0.5m, L\u2082 = 0.3m"}),"\n",(0,o.jsx)(n.li,{children:"Target end effector position: (x, y) = (0.6, 0.4)"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Inverse Kinematics (geometric approach)"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import numpy as np\r\n\r\ndef inverse_kinematics_2dof(x, y, L1, L2):\r\n    # Distance from origin to target\r\n    D = np.sqrt(x**2 + y**2)\r\n    \r\n    # Check reachability\r\n    if D > L1 + L2 or D < abs(L1 - L2):\r\n        raise ValueError("Target unreachable")\r\n    \r\n    # Angle \u03b82 (elbow angle)\r\n    cos_theta2 = (D**2 - L1**2 - L2**2) / (2 * L1 * L2)\r\n    theta2 = np.arccos(cos_theta2)  # Elbow-up solution\r\n    \r\n    # Angle \u03b81 (shoulder angle)\r\n    alpha = np.arctan2(y, x)\r\n    beta = np.arctan2(L2 * np.sin(theta2), L1 + L2 * np.cos(theta2))\r\n    theta1 = alpha - beta\r\n    \r\n    return theta1, theta2\r\n\r\n# Example\r\ntheta1, theta2 = inverse_kinematics_2dof(0.6, 0.4, 0.5, 0.3)\r\nprint(f"\u03b81 = {np.degrees(theta1):.2f}\xb0")\r\nprint(f"\u03b82 = {np.degrees(theta2):.2f}\xb0")\n'})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Note"}),": Multiple solutions exist (elbow-up vs elbow-down). Choose based on singularity avoidance and joint limits."]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"module-1-ros-2-ecosystem",children:"Module 1: ROS 2 Ecosystem"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Solutions will be added as Module 1 exercises are created"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"module-2-digital-twin",children:"Module 2: Digital Twin"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Solutions will be added as Module 2 exercises are created"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"module-3-nvidia-isaac",children:"Module 3: NVIDIA Isaac"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Solutions will be added as Module 3 exercises are created"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"module-4-vla-models",children:"Module 4: VLA Models"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Solutions will be added as Module 4 exercises are created"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"module-5-capstone-project",children:"Module 5: Capstone Project"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Solutions will be added as Module 5 exercises are created"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"additional-practice-problems",children:"Additional Practice Problems"}),"\n",(0,o.jsx)(n.p,{children:"For more practice problems and coding challenges, see:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"ROS 2 Tutorials"}),": ",(0,o.jsx)(n.a,{href:"https://docs.ros.org/en/humble/Tutorials.html",children:"https://docs.ros.org/en/humble/Tutorials.html"})]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Isaac Sim Tutorials"}),": ",(0,o.jsx)(n.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/latest/tutorials/index.html",children:"https://docs.omniverse.nvidia.com/isaacsim/latest/tutorials/index.html"})]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Robotics Stack Exchange"}),": ",(0,o.jsx)(n.a,{href:"https://robotics.stackexchange.com/",children:"https://robotics.stackexchange.com/"})]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}}}]);