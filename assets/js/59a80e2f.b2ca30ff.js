"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[5615],{28453:(n,e,r)=>{r.d(e,{R:()=>t,x:()=>l});var i=r(96540);const o={},s=i.createContext(o);function t(n){const e=i.useContext(s);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:t(n.components),i.createElement(s.Provider,{value:e},n.children)}},87950:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>a,contentTitle:()=>l,default:()=>p,frontMatter:()=>t,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"chapters/module-4-vla/policy-integration","title":"Chapter 3: Policy Integration","description":"Integrating VLA policies with ROS 2, safety wrappers, and real-world deployment","source":"@site/docs/chapters/module-4-vla/03-policy-integration.md","sourceDirName":"chapters/module-4-vla","slug":"/chapters/module-4-vla/policy-integration","permalink":"/Physical-AI-Humanoid-Robotics/docs/chapters/module-4-vla/policy-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/ayeshadev283-max/Physical-AI-Humanoid-Robotics/tree/main/docs/chapters/module-4-vla/03-policy-integration.md","tags":[{"inline":true,"label":"policy-integration","permalink":"/Physical-AI-Humanoid-Robotics/docs/tags/policy-integration"},{"inline":true,"label":"ros2","permalink":"/Physical-AI-Humanoid-Robotics/docs/tags/ros-2"},{"inline":true,"label":"safety","permalink":"/Physical-AI-Humanoid-Robotics/docs/tags/safety"},{"inline":true,"label":"deployment","permalink":"/Physical-AI-Humanoid-Robotics/docs/tags/deployment"},{"inline":true,"label":"robotics","permalink":"/Physical-AI-Humanoid-Robotics/docs/tags/robotics"}],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Chapter 3: Policy Integration","description":"Integrating VLA policies with ROS 2, safety wrappers, and real-world deployment","tags":["policy-integration","ros2","safety","deployment","robotics"]},"sidebar":"bookSidebar","previous":{"title":"Chapter 2: RT-2 and Open-Source VLA Models","permalink":"/Physical-AI-Humanoid-Robotics/docs/chapters/module-4-vla/rt2-models"},"next":{"title":"Chapter 4: Humanoid Skills with VLA","permalink":"/Physical-AI-Humanoid-Robotics/docs/chapters/module-4-vla/humanoid-skills"}}');var o=r(74848),s=r(28453);const t={sidebar_position:3,title:"Chapter 3: Policy Integration",description:"Integrating VLA policies with ROS 2, safety wrappers, and real-world deployment",tags:["policy-integration","ros2","safety","deployment","robotics"]},l="Chapter 3: Policy Integration",a={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"3.1 Policy-to-Robot Interface",id:"31-policy-to-robot-interface",level:2},{value:"Action Space Design",id:"action-space-design",level:3},{value:"Action Denormalization",id:"action-denormalization",level:3},{value:"ROS 2 Policy Node",id:"ros-2-policy-node",level:3},{value:"Control Frequencies",id:"control-frequencies",level:3},{value:"3.2 Safety Wrappers",id:"32-safety-wrappers",level:2},{value:"Workspace Limits",id:"workspace-limits",level:3},{value:"Collision Avoidance",id:"collision-avoidance",level:3},{value:"Emergency Stop",id:"emergency-stop",level:3},{value:"3.3 Real-World Deployment Considerations",id:"33-real-world-deployment-considerations",level:2},{value:"Latency Budget",id:"latency-budget",level:3},{value:"Failure Modes and Recovery",id:"failure-modes-and-recovery",level:3},{value:"Monitoring and Logging",id:"monitoring-and-logging",level:3},{value:"Sim-to-Real Validation",id:"sim-to-real-validation",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Summary",id:"summary",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"chapter-3-policy-integration",children:"Chapter 3: Policy Integration"})}),"\n",(0,o.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Integrate VLA policies with ROS 2 robot systems"}),"\n",(0,o.jsx)(e.li,{children:"Implement safety wrappers for collision avoidance and workspace limits"}),"\n",(0,o.jsx)(e.li,{children:"Address real-world deployment challenges (latency, failure modes, monitoring)"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"31-policy-to-robot-interface",children:"3.1 Policy-to-Robot Interface"}),"\n",(0,o.jsx)(e.h3,{id:"action-space-design",children:"Action Space Design"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"VLA Output"}),": Normalized actions in [-1, 1] per dimension"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Robot Input"}),": Task-specific action spaces"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Common Action Spaces"}),":"]}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"End-Effector Pose (6-DOF + Gripper)"}),":"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"action = [x, y, z, roll, pitch, yaw, gripper_state]  # (7,)\r\n# x, y, z: Position in meters (workspace frame)\r\n# roll, pitch, yaw: Orientation in radians\r\n# gripper_state: 0 = open, 1 = closed\n"})}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Joint Velocities"})," (7-DOF arm):"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"action = [j1_vel, j2_vel, ..., j7_vel, gripper_vel]  # (8,)\r\n# Joint velocities in rad/s\n"})}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Delta End-Effector"})," (relative motion):"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"action = [dx, dy, dz, droll, dpitch, dyaw, gripper]  # (7,)\r\n# Small incremental changes (e.g., \xb15cm, \xb110\xb0)\n"})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"action-denormalization",children:"Action Denormalization"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Mapping [-1, 1] \u2192 Real Units"}),":"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"import numpy as np\r\n\r\nclass ActionDenormalizer:\r\n    def __init__(self, action_space):\r\n        \"\"\"\r\n        Args:\r\n            action_space: Dict with 'low' and 'high' bounds\r\n\r\n        Example:\r\n            action_space = {\r\n                'low': np.array([-0.5, -0.5, 0.0, -3.14, -1.57, -3.14, 0.0]),\r\n                'high': np.array([0.5, 0.5, 0.5, 3.14, 1.57, 3.14, 1.0])\r\n            }\r\n        \"\"\"\r\n        self.low = np.array(action_space['low'])\r\n        self.high = np.array(action_space['high'])\r\n\r\n    def denormalize(self, normalized_action):\r\n        \"\"\"\r\n        Convert [-1, 1] \u2192 [low, high]\r\n\r\n        Args:\r\n            normalized_action: (n,) array in [-1, 1]\r\n\r\n        Returns:\r\n            real_action: (n,) array in [low, high]\r\n        \"\"\"\r\n        # Clip to [-1, 1]\r\n        clipped = np.clip(normalized_action, -1, 1)\r\n\r\n        # Linear mapping\r\n        real_action = self.low + (clipped + 1) / 2 * (self.high - self.low)\r\n\r\n        return real_action\r\n\r\n# Example usage\r\naction_space = {\r\n    'low': np.array([-0.5, -0.5, 0.0, -3.14, -1.57, -3.14, 0.0]),\r\n    'high': np.array([0.5, 0.5, 0.5, 3.14, 1.57, 3.14, 1.0])\r\n}\r\ndenormalizer = ActionDenormalizer(action_space)\r\n\r\n# VLA output\r\nvla_action = np.array([0.2, -0.5, 0.8, 0.0, 0.3, -0.1, 1.0])\r\n\r\n# Denormalize\r\nrobot_action = denormalizer.denormalize(vla_action)\r\nprint(robot_action)\r\n# [0.1, -0.375, 0.4, 0.0, -0.314, 2.984, 1.0]\n"})}),"\n",(0,o.jsx)(e.h3,{id:"ros-2-policy-node",children:"ROS 2 Policy Node"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Architecture"}),":"]}),"\n",(0,o.jsx)(e.mermaid,{value:'graph LR\r\n    Camera["/camera/image_raw<br/>sensor_msgs/Image"] --\x3e PolicyNode[VLA Policy Node]\r\n    Instruction["/task/instruction<br/>std_msgs/String"] --\x3e PolicyNode\r\n\r\n    PolicyNode --\x3e Action["/action/command<br/>control_msgs/JointTrajectoryPoint"]\r\n\r\n    Action --\x3e Controller[Robot Controller<br/>ros2_control]\r\n    Controller --\x3e Robot[Robot Hardware]\r\n\r\n    style PolicyNode fill:#e1f5ff\r\n    style Controller fill:#ffe1e1'}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Figure 3.1"}),": ROS 2 integration showing VLA policy node consuming camera and instruction topics, publishing action commands to robot controller."]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Implementation"}),":"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image\r\nfrom std_msgs.msg import String\r\nfrom control_msgs.msg import JointTrajectoryPoint\r\nfrom cv_bridge import CvBridge\r\nimport torch\r\nfrom openvla import OpenVLA\r\n\r\nclass VLAPolicyNode(Node):\r\n    def __init__(self):\r\n        super().__init__('vla_policy_node')\r\n\r\n        # Load VLA model\r\n        self.model = OpenVLA.from_pretrained(\"openvla-7b\").to(\"cuda\")\r\n        self.model.eval()\r\n\r\n        # ROS utilities\r\n        self.bridge = CvBridge()\r\n        self.current_image = None\r\n        self.current_instruction = \"pick up the cup\"  # Default\r\n\r\n        # Subscribers\r\n        self.image_sub = self.create_subscription(\r\n            Image,\r\n            '/camera/image_raw',\r\n            self.image_callback,\r\n            10\r\n        )\r\n        self.instruction_sub = self.create_subscription(\r\n            String,\r\n            '/task/instruction',\r\n            self.instruction_callback,\r\n            10\r\n        )\r\n\r\n        # Publisher\r\n        self.action_pub = self.create_publisher(\r\n            JointTrajectoryPoint,\r\n            '/action/command',\r\n            10\r\n        )\r\n\r\n        # Policy loop (10 Hz)\r\n        self.timer = self.create_timer(0.1, self.policy_loop)\r\n\r\n        self.get_logger().info(\"VLA Policy Node started\")\r\n\r\n    def image_callback(self, msg):\r\n        # Convert ROS Image to OpenCV format\r\n        self.current_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='rgb8')\r\n\r\n    def instruction_callback(self, msg):\r\n        self.current_instruction = msg.data\r\n        self.get_logger().info(f\"New instruction: {self.current_instruction}\")\r\n\r\n    def policy_loop(self):\r\n        if self.current_image is None:\r\n            return\r\n\r\n        # Predict action\r\n        with torch.no_grad():\r\n            action = self.model.predict_action(\r\n                image=self.current_image,\r\n                instruction=self.current_instruction,\r\n                unnormalize=True\r\n            )\r\n\r\n        # Publish action\r\n        msg = JointTrajectoryPoint()\r\n        msg.positions = action[:7].tolist()  # Joint positions or EE pose\r\n        msg.time_from_start.sec = 0\r\n        msg.time_from_start.nanosec = 100_000_000  # 100ms\r\n\r\n        self.action_pub.publish(msg)\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = VLAPolicyNode()\r\n    rclpy.spin(node)\r\n    node.destroy_node()\r\n    rclpy.shutdown()\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n",(0,o.jsx)(e.h3,{id:"control-frequencies",children:"Control Frequencies"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Policy Frequency"}),": 10 Hz (typical for VLA models)"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Inference time: 20-50ms (OpenVLA on GPU)"}),"\n",(0,o.jsx)(e.li,{children:"Remaining budget: 50-80ms for processing"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Robot Control Frequency"}),": 100-1000 Hz (joint-level control)"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"High-level commands (10 Hz) \u2192 Low-level tracking (1000 Hz)"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Bridging Frequencies"}),":"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'class FrequencyBridge:\r\n    def __init__(self, policy_hz=10, control_hz=1000):\r\n        self.policy_hz = policy_hz\r\n        self.control_hz = control_hz\r\n        self.steps_per_action = control_hz // policy_hz  # 100 steps\r\n\r\n    def interpolate_action(self, prev_action, next_action, step):\r\n        """\r\n        Linear interpolation between actions\r\n\r\n        Args:\r\n            prev_action: Previous VLA output\r\n            next_action: Current VLA output\r\n            step: Current step in [0, steps_per_action-1]\r\n\r\n        Returns:\r\n            interpolated_action: Smooth action for this timestep\r\n        """\r\n        alpha = step / self.steps_per_action\r\n        return (1 - alpha) * prev_action + alpha * next_action\n'})}),"\n",(0,o.jsx)(e.h2,{id:"32-safety-wrappers",children:"3.2 Safety Wrappers"}),"\n",(0,o.jsx)(e.h3,{id:"workspace-limits",children:"Workspace Limits"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Problem"}),": VLA may command unsafe positions (outside reachable workspace)"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Solution"}),": Clip actions to safe bounds"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"class WorkspaceSafetyWrapper:\r\n    def __init__(self, workspace_bounds):\r\n        \"\"\"\r\n        Args:\r\n            workspace_bounds: Dict with 'position' and 'orientation' limits\r\n\r\n        Example:\r\n            bounds = {\r\n                'position': {'min': [-0.5, -0.5, 0.0], 'max': [0.5, 0.5, 0.6]},\r\n                'orientation': {'min': [-3.14, -1.57, -3.14], 'max': [3.14, 1.57, 3.14]}\r\n            }\r\n        \"\"\"\r\n        self.pos_min = np.array(workspace_bounds['position']['min'])\r\n        self.pos_max = np.array(workspace_bounds['position']['max'])\r\n        self.ori_min = np.array(workspace_bounds['orientation']['min'])\r\n        self.ori_max = np.array(workspace_bounds['orientation']['max'])\r\n\r\n    def clip_action(self, action):\r\n        \"\"\"\r\n        Clip action to workspace bounds\r\n\r\n        Args:\r\n            action: (7,) [x, y, z, roll, pitch, yaw, gripper]\r\n\r\n        Returns:\r\n            clipped_action: Safe action within bounds\r\n        \"\"\"\r\n        safe_action = action.copy()\r\n\r\n        # Clip position (xyz)\r\n        safe_action[:3] = np.clip(action[:3], self.pos_min, self.pos_max)\r\n\r\n        # Clip orientation (rpy)\r\n        safe_action[3:6] = np.clip(action[3:6], self.ori_min, self.ori_max)\r\n\r\n        # Gripper unchanged\r\n        safe_action[6] = np.clip(action[6], 0, 1)\r\n\r\n        return safe_action\n"})}),"\n",(0,o.jsx)(e.h3,{id:"collision-avoidance",children:"Collision Avoidance"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Real-time collision checking"})," with robot environment:"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import pybullet as p\r\n\r\nclass CollisionChecker:\r\n    def __init__(self, robot_urdf, obstacle_urdfs):\r\n        """\r\n        Initialize PyBullet for collision checking\r\n\r\n        Args:\r\n            robot_urdf: Path to robot URDF\r\n            obstacle_urdfs: List of paths to obstacle URDFs\r\n        """\r\n        p.connect(p.DIRECT)  # Headless\r\n        self.robot_id = p.loadURDF(robot_urdf)\r\n        self.obstacle_ids = [p.loadURDF(urdf) for urdf in obstacle_urdfs]\r\n\r\n    def check_collision(self, joint_positions):\r\n        """\r\n        Check if joint configuration causes collision\r\n\r\n        Args:\r\n            joint_positions: (n,) array of joint angles\r\n\r\n        Returns:\r\n            is_collision: True if collision detected\r\n        """\r\n        # Set robot state\r\n        for i, pos in enumerate(joint_positions):\r\n            p.resetJointState(self.robot_id, i, pos)\r\n\r\n        # Check collisions\r\n        for obstacle_id in self.obstacle_ids:\r\n            contacts = p.getContactPoints(self.robot_id, obstacle_id)\r\n            if len(contacts) > 0:\r\n                return True  # Collision\r\n\r\n        return False  # Safe\r\n\r\n    def filter_safe_action(self, current_joints, target_action, num_checks=10):\r\n        """\r\n        Filter action to avoid collisions via interpolation\r\n\r\n        Args:\r\n            current_joints: Current joint positions\r\n            target_action: Desired joint positions from VLA\r\n            num_checks: Number of intermediate points to check\r\n\r\n        Returns:\r\n            safe_action: Closest collision-free action\r\n        """\r\n        for i in range(num_checks + 1):\r\n            alpha = i / num_checks\r\n            interpolated = (1 - alpha) * current_joints + alpha * target_action\r\n\r\n            if self.check_collision(interpolated):\r\n                # Collision detected, return previous safe point\r\n                safe_alpha = max(0, (i - 1) / num_checks)\r\n                return (1 - safe_alpha) * current_joints + safe_alpha * target_action\r\n\r\n        return target_action  # All checks passed\n'})}),"\n",(0,o.jsx)(e.h3,{id:"emergency-stop",children:"Emergency Stop"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Conditions for E-stop"}),":"]}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Force/torque limits exceeded (gripper crushing object)"}),"\n",(0,o.jsx)(e.li,{children:"Joint limits violated"}),"\n",(0,o.jsx)(e.li,{children:"Communication timeout (policy node crashed)"}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'class EmergencyStop:\r\n    def __init__(self, force_limit=50.0, timeout=0.5):\r\n        """\r\n        Args:\r\n            force_limit: Max force in Newtons\r\n            timeout: Max time without policy update (seconds)\r\n        """\r\n        self.force_limit = force_limit\r\n        self.timeout = timeout\r\n        self.last_update_time = time.time()\r\n\r\n    def check_safety(self, force_reading, joint_positions, joint_limits):\r\n        """\r\n        Returns:\r\n            (is_safe, reason)\r\n        """\r\n        # Check force\r\n        if np.any(np.abs(force_reading) > self.force_limit):\r\n            return False, "Force limit exceeded"\r\n\r\n        # Check joint limits\r\n        if np.any(joint_positions < joint_limits[\'min\']) or \\\r\n           np.any(joint_positions > joint_limits[\'max\']):\r\n            return False, "Joint limit violated"\r\n\r\n        # Check timeout\r\n        if time.time() - self.last_update_time > self.timeout:\r\n            return False, "Policy timeout"\r\n\r\n        return True, "OK"\r\n\r\n    def update_timestamp(self):\r\n        self.last_update_time = time.time()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"33-real-world-deployment-considerations",children:"3.3 Real-World Deployment Considerations"}),"\n",(0,o.jsx)(e.h3,{id:"latency-budget",children:"Latency Budget"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Total Latency"}),": Perception \u2192 Action"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Camera capture"}),": 16ms (60 FPS)"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Encoding/preprocessing"}),": 5ms"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"VLA inference"}),": 20-50ms (GPU), 100ms (CPU)"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Action denormalization"}),": ",(0,o.jsx)(e.code,{children:"<1ms"})]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ROS 2 messaging"}),": 1-5ms"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Robot control"}),": 1ms"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Total"}),": 50-80ms (12-20 Hz control loop)"]}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Latency Optimization"}),":"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"import torch\r\n\r\n# 1. Use FP16 inference (2x speedup)\r\nmodel = model.half()  # Convert to FP16\r\n\r\n# 2. TensorRT compilation (3-5x speedup)\r\nimport torch_tensorrt\r\n\r\ntrt_model = torch_tensorrt.compile(\r\n    model,\r\n    inputs=[torch_tensorrt.Input((1, 3, 224, 224))],\r\n    enabled_precisions={torch.float16}\r\n)\r\n\r\n# 3. Batch processing (if multiple cameras)\r\nactions = model(images_batch)  # Process all cameras at once\n"})}),"\n",(0,o.jsx)(e.h3,{id:"failure-modes-and-recovery",children:"Failure Modes and Recovery"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Common Failures"}),":"]}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Perception Failure"}),": Object not detected"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def handle_perception_failure(confidence):\r\n    if confidence < 0.5:\r\n        # Request human demonstration\r\n        return "teleop_mode"\n'})}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Grasp Failure"}),": Object slipped"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def detect_grasp_failure(gripper_force, expected_weight):\r\n    if gripper_force < 0.5 * expected_weight:\r\n        # Retry grasp with tighter grip\r\n        return "retry_grasp"\n'})}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Policy Uncertainty"}),": Low confidence action"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def check_policy_confidence(action_distribution):\r\n    entropy = -torch.sum(action_distribution * torch.log(action_distribution))\r\n    if entropy > 2.0:  # High uncertainty\r\n        return "request_human_help"\n'})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"monitoring-and-logging",children:"Monitoring and Logging"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Real-time Metrics"}),":"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"class PolicyMonitor:\r\n    def __init__(self):\r\n        self.metrics = {\r\n            'inference_time': [],\r\n            'action_magnitude': [],\r\n            'safety_violations': 0,\r\n            'success_rate': []\r\n        }\r\n\r\n    def log_inference(self, inference_time, action):\r\n        self.metrics['inference_time'].append(inference_time)\r\n        self.metrics['action_magnitude'].append(np.linalg.norm(action))\r\n\r\n    def log_safety_violation(self):\r\n        self.metrics['safety_violations'] += 1\r\n\r\n    def log_task_outcome(self, success):\r\n        self.metrics['success_rate'].append(1.0 if success else 0.0)\r\n\r\n    def get_summary(self):\r\n        return {\r\n            'avg_latency_ms': np.mean(self.metrics['inference_time']) * 1000,\r\n            'p95_latency_ms': np.percentile(self.metrics['inference_time'], 95) * 1000,\r\n            'safety_violations': self.metrics['safety_violations'],\r\n            'success_rate': np.mean(self.metrics['success_rate'][-100:])  # Last 100 tasks\r\n        }\n"})}),"\n",(0,o.jsx)(e.h3,{id:"sim-to-real-validation",children:"Sim-to-Real Validation"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Checklist before real-world deployment"}),":"]}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"\u2705 Test in simulation (Isaac Sim, Gazebo) with domain randomization"}),"\n",(0,o.jsx)(e.li,{children:"\u2705 Validate safety wrappers with edge cases"}),"\n",(0,o.jsx)(e.li,{children:"\u2705 Benchmark latency on target hardware (Jetson, workstation)"}),"\n",(0,o.jsx)(e.li,{children:"\u2705 Collect initial demonstrations on real robot (fine-tune if needed)"}),"\n",(0,o.jsx)(e.li,{children:"\u2705 Start with simple tasks (pick-and-place known objects)"}),"\n",(0,o.jsx)(e.li,{children:"\u2705 Human supervisor ready for e-stop (first 100 runs)"}),"\n",(0,o.jsx)(e.li,{children:"\u2705 Log all failures and update policy/safety rules"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Exercise 3.1"}),": ROS 2 Policy Integration"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Implement VLA policy node in ROS 2 (code above)"}),"\n",(0,o.jsx)(e.li,{children:"Connect to simulated robot (Gazebo or Isaac Sim)"}),"\n",(0,o.jsx)(e.li,{children:"Test latency: measure end-to-end time from image \u2192 action execution"}),"\n",(0,o.jsxs)(e.li,{children:["Optimize to achieve ",(0,o.jsx)(e.code,{children:"<50ms"})," latency"]}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Exercise 3.2"}),": Safety Wrapper Implementation"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Implement workspace limits and collision checking"}),"\n",(0,o.jsx)(e.li,{children:"Test with intentionally unsafe actions (outside bounds, collision paths)"}),"\n",(0,o.jsx)(e.li,{children:"Measure false positive rate (safe actions rejected) and false negative rate (unsafe actions allowed)"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Exercise 3.3"}),": Failure Mode Analysis"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Simulate 3 failure modes: perception failure, grasp failure, policy uncertainty"}),"\n",(0,o.jsx)(e.li,{children:"Implement recovery strategies for each"}),"\n",(0,o.jsx)(e.li,{children:"Measure recovery success rate"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Exercise 3.4"}),": Real-World Deployment"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Deploy VLA policy on real robot (if available) or high-fidelity sim"}),"\n",(0,o.jsx)(e.li,{children:"Run 50 pick-and-place tasks"}),"\n",(0,o.jsx)(e.li,{children:"Log: success rate, latency, safety violations, failure modes"}),"\n",(0,o.jsx)(e.li,{children:"Create deployment report with recommendations"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Policy-Robot Interface"}),": Action denormalization, ROS 2 integration, frequency bridging (10 Hz \u2192 1000 Hz)\r\n",(0,o.jsx)(e.strong,{children:"Safety Wrappers"}),": Workspace limits, collision avoidance, emergency stop\r\n",(0,o.jsx)(e.strong,{children:"Deployment"}),": Latency optimization (",(0,o.jsx)(e.code,{children:"<50ms"}),"), failure recovery, monitoring, sim-to-real validation"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Next"}),": Chapter 4 covers humanoid-specific skills (manipulation, locomotion, multi-task learning)."]})]})}function p(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}}}]);