"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[7622],{3769:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>a});const r=JSON.parse('{"id":"chapters/module-2-digital-twin/unity-animation","title":"Chapter 3: Unity Animation and Rendering","description":"Unity Robotics Hub, articulation bodies, and ML-Agents","source":"@site/docs/chapters/module-2-digital-twin/03-unity-animation.md","sourceDirName":"chapters/module-2-digital-twin","slug":"/chapters/module-2-digital-twin/unity-animation","permalink":"/Physical-AI-Humanoid-Robotics/chapters/module-2-digital-twin/unity-animation","draft":false,"unlisted":false,"editUrl":"https://github.com/ayeshadev283-max/Physical-AI-Humanoid-Robotics/tree/main/docs/chapters/module-2-digital-twin/03-unity-animation.md","tags":[{"inline":true,"label":"unity","permalink":"/Physical-AI-Humanoid-Robotics/tags/unity"},{"inline":true,"label":"robotics-hub","permalink":"/Physical-AI-Humanoid-Robotics/tags/robotics-hub"},{"inline":true,"label":"articulation-bodies","permalink":"/Physical-AI-Humanoid-Robotics/tags/articulation-bodies"},{"inline":true,"label":"ml-agents","permalink":"/Physical-AI-Humanoid-Robotics/tags/ml-agents"},{"inline":true,"label":"rendering","permalink":"/Physical-AI-Humanoid-Robotics/tags/rendering"}],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Chapter 3: Unity Animation and Rendering","description":"Unity Robotics Hub, articulation bodies, and ML-Agents","tags":["unity","robotics-hub","articulation-bodies","ml-agents","rendering"]},"sidebar":"bookSidebar","previous":{"title":"Chapter 2: Gazebo Physics","permalink":"/Physical-AI-Humanoid-Robotics/chapters/module-2-digital-twin/gazebo-physics"},"next":{"title":"Chapter 4: ROS 2 Integration","permalink":"/Physical-AI-Humanoid-Robotics/chapters/module-2-digital-twin/ros2-integration"}}');var s=i(74848),t=i(28453);const o={sidebar_position:3,title:"Chapter 3: Unity Animation and Rendering",description:"Unity Robotics Hub, articulation bodies, and ML-Agents",tags:["unity","robotics-hub","articulation-bodies","ml-agents","rendering"]},l="Chapter 3: Unity Animation and Rendering",c={},a=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"3.1 Unity Robotics Hub",id:"31-unity-robotics-hub",level:2},{value:"Overview",id:"overview",level:3},{value:"Installation",id:"installation",level:3},{value:"URDF Import Workflow",id:"urdf-import-workflow",level:3},{value:"ROS-TCP-Connector Setup",id:"ros-tcp-connector-setup",level:3},{value:"3.2 Animation and Rendering",id:"32-animation-and-rendering",level:2},{value:"Articulation Bodies",id:"articulation-bodies",level:3},{value:"High-Fidelity Rendering",id:"high-fidelity-rendering",level:3},{value:"Unity ML-Agents",id:"unity-ml-agents",level:3},{value:"3.3 Unity vs Gazebo",id:"33-unity-vs-gazebo",level:2},{value:"When to Use Unity",id:"when-to-use-unity",level:3},{value:"When to Use Gazebo",id:"when-to-use-gazebo",level:3},{value:"Comparison Table",id:"comparison-table",level:3},{value:"Hybrid Approach",id:"hybrid-approach",level:3},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"chapter-3-unity-animation-and-rendering",children:"Chapter 3: Unity Animation and Rendering"})}),"\n",(0,s.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Use Unity Robotics Hub to import URDF and connect to ROS 2"}),"\n",(0,s.jsx)(e.li,{children:"Configure articulation bodies for realistic robot physics"}),"\n",(0,s.jsx)(e.li,{children:"Compare Unity and Gazebo to select the appropriate tool"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"31-unity-robotics-hub",children:"3.1 Unity Robotics Hub"}),"\n",(0,s.jsx)(e.h3,{id:"overview",children:"Overview"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Unity Robotics Hub"}),": Open-source package for integrating Unity with ROS/ROS 2"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Components"}),":"]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"URDF Importer"}),": Convert URDF \u2192 Unity GameObjects"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"ROS-TCP-Connector"}),": Bidirectional message passing (Unity \u2194 ROS 2)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Visualizations"}),": Sensor data rendering (point clouds, markers)"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Why Unity for Robotics?"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Photorealistic rendering"}),": Real-time ray tracing, global illumination"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"High-performance"}),": Optimized for games (60+ FPS with complex scenes)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Cross-platform"}),": Desktop, mobile, VR/AR, cloud"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Asset ecosystem"}),": 3D models, environments (Unity Asset Store)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"ML-Agents"}),": Reinforcement learning framework (Unity ML-Agents)"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"installation",children:"Installation"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Unity Hub + Unity Editor (2021.3 LTS recommended)\r\n# Install via Unity Hub: https://unity.com/download\r\n\r\n# Add packages via Package Manager\r\n# 1. URDF Importer: com.unity.robotics.urdf-importer\r\n# 2. ROS-TCP-Connector: com.unity.robotics.ros-tcp-connector\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"ROS 2 Side"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"sudo apt install ros-humble-ros-tcp-endpoint\r\nros2 run ros_tcp_endpoint default_server_endpoint --ros-args -p ROS_IP:=0.0.0.0\n"})}),"\n",(0,s.jsx)(e.h3,{id:"urdf-import-workflow",children:"URDF Import Workflow"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 1: Prepare URDF"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Ensure mesh files (STL, OBJ, DAE) are referenced correctly"}),"\n",(0,s.jsxs)(e.li,{children:["Use relative paths: ",(0,s.jsx)(e.code,{children:"package://robot_description/meshes/base.stl"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 2: Import in Unity"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Assets \u2192 Import Robot from URDF\r\nSelect URDF file\r\nConfigure import settings:\r\n  - Axis Convention: Y-up (Unity) or Z-up (ROS)\r\n  - Mesh Decomposition: Convex (for collision)\r\n  - Material: Standard (PBR)\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 3: Articulation Body Conversion"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Unity auto-creates ArticulationBody components for joints"}),"\n",(0,s.jsx)(e.li,{children:"Hierarchy: Root (immovable) \u2192 links connected by articulations"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Example Hierarchy"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Robot_Root (ArticulationBody: Fixed)\r\n\u251c\u2500\u2500 base_link\r\n\u2502   \u251c\u2500\u2500 left_wheel (ArticulationBody: Continuous)\r\n\u2502   \u251c\u2500\u2500 right_wheel (ArticulationBody: Continuous)\r\n\u2502   \u2514\u2500\u2500 camera_link (ArticulationBody: Fixed)\n"})}),"\n",(0,s.jsx)(e.h3,{id:"ros-tcp-connector-setup",children:"ROS-TCP-Connector Setup"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Unity Side"})," (C# script):"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-csharp",children:'using Unity.Robotics.ROSTCPConnector;\r\nusing RosMessageTypes.Geometry;\r\n\r\npublic class RobotController : MonoBehaviour\r\n{\r\n    ROSConnection ros;\r\n\r\n    void Start()\r\n    {\r\n        ros = ROSConnection.GetOrCreateInstance();\r\n        ros.RegisterPublisher<TwistMsg>("cmd_vel");\r\n        ros.Subscribe<TwistMsg>("unity/cmd_vel", OnCmdVel);\r\n    }\r\n\r\n    void OnCmdVel(TwistMsg msg)\r\n    {\r\n        // Apply velocity to robot\r\n        float linear = (float)msg.linear.x;\r\n        float angular = (float)msg.angular.z;\r\n        // ...control logic\r\n    }\r\n\r\n    void PublishOdometry()\r\n    {\r\n        var odom = new TwistMsg();\r\n        // ...populate odom\r\n        ros.Publish("odom", odom);\r\n    }\r\n}\n'})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"ROS 2 Side"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'# Start TCP endpoint\r\nros2 run ros_tcp_endpoint default_server_endpoint\r\n\r\n# Publish to Unity\r\nros2 topic pub /unity/cmd_vel geometry_msgs/Twist "{linear: {x: 0.5}, angular: {z: 0.1}}"\r\n\r\n# Subscribe from Unity\r\nros2 topic echo /odom\n'})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Message Types"}),": Auto-generated from ROS .msg files"]}),"\n",(0,s.jsx)(e.h2,{id:"32-animation-and-rendering",children:"3.2 Animation and Rendering"}),"\n",(0,s.jsx)(e.h3,{id:"articulation-bodies",children:"Articulation Bodies"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Unity Physics"}),": PhysX (NVIDIA's physics engine)"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"ArticulationBody"}),": Unity's component for robotic joints (replaces older Rigidbody chains)"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Advantages"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Reduced jitter (stable multi-body dynamics)"}),"\n",(0,s.jsx)(e.li,{children:"Direct joint control (position, velocity, force)"}),"\n",(0,s.jsx)(e.li,{children:"Better for high-DOF robots (humanoids, manipulators)"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Joint Types"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Fixed"}),": Welded (sensor mounts)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Revolute"}),": Hinge with limits"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Prismatic"}),": Linear slide"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Spherical"}),": Ball joint (3-DOF)"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Configuration"})," (via Unity Inspector):"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"ArticulationBody Component:\r\n  - Anchor Position/Rotation: Joint origin\r\n  - Joint Type: Revolute/Prismatic/Fixed\r\n  - X/Y/Z Motion: Locked/Limited/Free\r\n  - Limits: Min/Max angle (revolute), Min/Max distance (prismatic)\r\n  - Stiffness: PD controller gains\r\n  - Damping: Velocity damping\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Control Modes"}),":"]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Force"}),": Apply torque, physics computes motion"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Acceleration"}),": Set target acceleration"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Velocity"}),": PD controller to target velocity"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Position"}),": PD controller to target angle"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Example"})," (setting joint velocity):"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-csharp",children:"ArticulationBody joint = GetComponent<ArticulationBody>();\r\nvar drive = joint.xDrive;\r\ndrive.target = 2.0f;  // rad/s (for revolute)\r\ndrive.targetVelocity = 2.0f;\r\njoint.xDrive = drive;\n"})}),"\n",(0,s.jsx)(e.h3,{id:"high-fidelity-rendering",children:"High-Fidelity Rendering"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Physically Based Rendering (PBR)"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Metallic/Roughness workflow"}),"\n",(0,s.jsx)(e.li,{children:"Realistic materials (metal, plastic, rubber)"}),"\n",(0,s.jsx)(e.li,{children:"HDRP (High Definition Render Pipeline) for ray tracing"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Lighting"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Directional Light"}),": Sunlight (parallel rays)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Point Light"}),": Omnidirectional (lightbulb)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Spot Light"}),": Cone-shaped (flashlight)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Area Light"}),": Soft shadows (HDRP only)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Global Illumination"}),": Indirect lighting (baked lightmaps)"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Post-Processing"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Bloom, lens flare, motion blur"}),"\n",(0,s.jsx)(e.li,{children:"Color grading, vignette"}),"\n",(0,s.jsx)(e.li,{children:"Depth of field (focus on robot, blur background)"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Camera Simulation"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-csharp",children:"// Capture camera feed\r\nCamera cam = GetComponent<Camera>();\r\nRenderTexture rt = new RenderTexture(640, 480, 24);\r\ncam.targetTexture = rt;\r\ncam.Render();\r\n\r\n// Read pixels \u2192 publish to ROS\r\nTexture2D tex = new Texture2D(640, 480, TextureFormat.RGB24, false);\r\nRenderTexture.active = rt;\r\ntex.ReadPixels(new Rect(0, 0, 640, 480), 0, 0);\r\ntex.Apply();\r\n\r\n// Convert to sensor_msgs/Image\r\nbyte[] bytes = tex.GetRawTextureData();\r\n// ...publish via ROS-TCP-Connector\n"})}),"\n",(0,s.jsx)(e.h3,{id:"unity-ml-agents",children:"Unity ML-Agents"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"ML-Agents"}),": Reinforcement learning framework for Unity"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Architecture"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 Python Trainer  \u2502 (PyTorch/TensorFlow)\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n         \u2502 RPC (grpc)\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 Unity C# Agent  \u2502 (Environment)\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Agent Example"})," (robot navigation):"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-csharp",children:"using Unity.MLAgents;\r\nusing Unity.MLAgents.Sensors;\r\nusing Unity.MLAgents.Actuators;\r\n\r\npublic class RobotAgent : Agent\r\n{\r\n    public Transform target;\r\n\r\n    public override void OnEpisodeBegin()\r\n    {\r\n        // Reset robot position, randomize target\r\n        transform.position = new Vector3(0, 0, 0);\r\n        target.position = Random.insideUnitSphere * 5f;\r\n    }\r\n\r\n    public override void CollectObservations(VectorSensor sensor)\r\n    {\r\n        // State: robot pos, target pos, robot velocity\r\n        sensor.AddObservation(transform.position);\r\n        sensor.AddObservation(target.position);\r\n        sensor.AddObservation(GetComponent<Rigidbody>().velocity);\r\n    }\r\n\r\n    public override void OnActionReceived(ActionBuffers actions)\r\n    {\r\n        // Actions: linear/angular velocity\r\n        float linear = actions.ContinuousActions[0];\r\n        float angular = actions.ContinuousActions[1];\r\n\r\n        // Apply to robot\r\n        rb.AddForce(transform.forward * linear * speed);\r\n        rb.AddTorque(Vector3.up * angular * torque);\r\n\r\n        // Reward: distance to target\r\n        float dist = Vector3.Distance(transform.position, target.position);\r\n        if (dist < 0.5f) {\r\n            SetReward(1.0f);\r\n            EndEpisode();\r\n        } else {\r\n            SetReward(-0.01f * dist);\r\n        }\r\n    }\r\n}\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Training"})," (Python):"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"mlagents-learn config.yaml --run-id=robot_nav_01\r\n# Play in Unity Editor \u2192 agent learns\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Benefits"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Parallel environments (1000s of robots in one scene)"}),"\n",(0,s.jsx)(e.li,{children:"Curriculum learning (progressively harder tasks)"}),"\n",(0,s.jsx)(e.li,{children:"Imitation learning (demonstrations \u2192 policy)"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"33-unity-vs-gazebo",children:"3.3 Unity vs Gazebo"}),"\n",(0,s.jsx)(e.h3,{id:"when-to-use-unity",children:"When to Use Unity"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Advantages"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Visuals"}),": Photorealistic (ray tracing, PBR)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Performance"}),": Faster rendering (optimized for games)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Cross-platform"}),": VR/AR support, mobile deployment"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Asset ecosystem"}),": Pre-built environments, objects"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"ML-Agents"}),": Integrated RL framework"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Use Cases"}),":"]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Synthetic data generation"}),": Train computer vision models"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Human-robot interaction"}),": VR teleoperation, AR overlays"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Marketing/demos"}),": Photorealistic videos for presentations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Large-scale RL"}),": 1000s of parallel agents"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Mobile/AR robotics"}),": Visualize robot in real environment (ARCore/ARKit)"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"when-to-use-gazebo",children:"When to Use Gazebo"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Advantages"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Physics accuracy"}),": DART engine for manipulation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"ROS 2 integration"}),": Native, no TCP bridge"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Sensor fidelity"}),": Realistic LiDAR, radar models"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Open-source"}),": Free, community-maintained"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Determinism"}),": Reproducible results (critical for research)"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Use Cases"}),":"]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Contact-rich tasks"}),": Manipulation, grasping, assembly"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Legged locomotion"}),": Accurate foot contacts"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"ROS 2 ecosystem"}),": Seamless integration with Nav2, MoveIt"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Research"}),": Deterministic experiments, open-source transparency"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Deployment testing"}),": Closest to hardware behavior"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"comparison-table",children:"Comparison Table"}),"\n",(0,s.jsxs)(e.table,{children:[(0,s.jsx)(e.thead,{children:(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.th,{children:"Feature"}),(0,s.jsx)(e.th,{children:"Unity"}),(0,s.jsx)(e.th,{children:"Gazebo"})]})}),(0,s.jsxs)(e.tbody,{children:[(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"Rendering"})}),(0,s.jsx)(e.td,{children:"Photorealistic"}),(0,s.jsx)(e.td,{children:"Basic"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"Physics Accuracy"})}),(0,s.jsx)(e.td,{children:"Medium"}),(0,s.jsx)(e.td,{children:"High (DART)"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"ROS 2 Integration"})}),(0,s.jsx)(e.td,{children:"TCP bridge"}),(0,s.jsx)(e.td,{children:"Native"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"Performance"})}),(0,s.jsx)(e.td,{children:"Fast (60+ FPS)"}),(0,s.jsx)(e.td,{children:"Medium"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"RL Support"})}),(0,s.jsx)(e.td,{children:"ML-Agents"}),(0,s.jsx)(e.td,{children:"External (Isaac, etc)"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"License"})}),(0,s.jsx)(e.td,{children:"Free (Personal)"}),(0,s.jsx)(e.td,{children:"Open-source"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"Best For"})}),(0,s.jsx)(e.td,{children:"Vision, VR/AR, ML"}),(0,s.jsx)(e.td,{children:"Manipulation, locomotion"})]})]})]}),"\n",(0,s.jsx)(e.h3,{id:"hybrid-approach",children:"Hybrid Approach"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Scenario"}),": Train vision policy in Unity, validate control in Gazebo"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Workflow"}),":"]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Unity"}),": Generate synthetic images (domain randomization)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Train"}),": Object detection model (YOLOv8, Mask R-CNN)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Gazebo"}),": Deploy detector + motion planner"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Validate"}),": Pick-and-place task with accurate physics"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Transfer"}),": Real robot with fine-tuning"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Example"}),": Amazon Robotics Challenge"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Unity for vision training (synthetic shelves with varied products)"}),"\n",(0,s.jsx)(e.li,{children:"Gazebo for grasp planning (DART physics for contact)"}),"\n",(0,s.jsx)(e.li,{children:"Real robot deployment"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Unity Robotics Hub"}),": URDF import, ROS-TCP-Connector for ROS 2 integration\r\n",(0,s.jsx)(e.strong,{children:"Articulation Bodies"}),": PhysX-based robot physics with joint control\r\n",(0,s.jsx)(e.strong,{children:"Unity vs Gazebo"}),": Unity (visuals, RL, VR) vs Gazebo (accuracy, ROS 2 native)"]}),"\n",(0,s.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Exercise 3.1"}),": Import a robot URDF into Unity and configure ArticulationBody components for a 3-DOF arm (base rotation, shoulder, elbow). Set joint limits, stiffness, and damping. Verify the robot can reach a target position using position control."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Exercise 3.2"}),": Implement a Unity ML-Agents environment for robot navigation. The agent should:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Observe: Robot position, target position, obstacle positions"}),"\n",(0,s.jsx)(e.li,{children:"Act: Linear and angular velocity commands"}),"\n",(0,s.jsx)(e.li,{children:"Reward: +1 for reaching target, -0.01 per timestep, -1 for collision\r\nTrain with PPO for 1M steps and measure success rate."}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Exercise 3.3"}),": Generate synthetic data for object detection. Create a Unity scene with 100 random objects (varying poses, lighting, backgrounds). Capture 10k images with bounding box annotations. Train YOLOv8 and measure mAP@0.5."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Exercise 3.4"}),": Compare Unity and Gazebo for a specific robot task (your choice). Measure:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Rendering performance (FPS)"}),"\n",(0,s.jsx)(e.li,{children:"Physics accuracy (e.g., contact force errors)"}),"\n",(0,s.jsx)(e.li,{children:"ROS 2 integration latency (message round-trip time)"}),"\n",(0,s.jsx)(e.li,{children:"Ease of use (subjective, but document setup time)\r\nPresent findings in a table with recommendations."}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Next"}),": Chapter 4 integrates Gazebo and Unity with ROS 2 for multi-simulator workflows."]})]})}function h(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}},28453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>l});var r=i(96540);const s={},t=r.createContext(s);function o(n){const e=r.useContext(t);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:o(n.components),r.createElement(t.Provider,{value:e},n.children)}}}]);